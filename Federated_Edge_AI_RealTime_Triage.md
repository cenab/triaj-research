# Federated Edge AI for Real-Time Triage Decision Support with Structured Data and LLM Integration

Emergency department triage is a critical process where quick, accurate decisions can save lives. We propose a novel real-time triage decision support system powered by advanced AI/ML, designed to assist triage staff using structured Boolean data (e.g., yes/no symptoms, vital sign flags) from adult and pediatric patients. The system is architected for edge deployment in a hospital, with an option to simulate federated learning across sites. To meet the high standards of IEEE Journal of Biomedical and Health Informatics (JBHI), our design emphasizes generalizability, transparency, and clinical relevance. Key innovations include synthetic data augmentation for multi-site robustness, an explainable multimodal model architecture (with potential LLM-enhanced explanation modules), on-device intelligence for low latency, privacy-preserving federated training, rigorous validation (clinical and user-centric), open science practices, and exploratory research into fairness, interpretability, and model efficiency. Below, we detail these components and enhancements:

---

## Expand Data Diversity and Realism

Triage models trained on a single-hospital dataset risk learning site-specific biases and may not generalize elsewhere. We will therefore broaden the data diversity and simulate a multi-site environment to improve realism:

- **Synthetic Multi-Site Data Generation:** Using generative modeling and controlled simulation, we will create realistic synthetic triage datasets that mimic other hospitals' populations and conditions. Recent work shows that structured synthetic data can be tailored to introduce site-specific differences in demographics, prevalence, and practice patterns. For example, we can generate a pediatric-heavy "hospital B" dataset or one with different disease prevalence. This approach provides explicit control over distribution shifts (e.g. varying symptom frequencies) to stress-test the model's generalizability. It enables targeted experiments on how the model handles new conditions and supports fairness audits under diverse scenarios without requiring real multi-center data.
- **Domain Adaptation for Generalization:** We will incorporate domain adaptation techniques to bridge the gap between the original hospital data and out-of-domain (simulated) data. For instance, the model could employ transfer learning – first trained on the base hospital data, then fine-tuned on synthetic "new site" data – to learn site-invariant features. By testing on varied synthetic sites, we address the known issue that many ML models falter on external cohorts. Our approach essentially provides a dry-run for external validation within a single-institution setting. We will also adjust decision thresholds or calibration per domain if needed, improving external validity.
- **Continuous Drift Monitoring:** Even within one hospital, patient populations and triage practices evolve over time. The system will include a data drift detection module that monitors incoming triage data for significant shifts from the training distribution. Data drift (whether due to seasonal illness spikes, protocol changes, or population shifts) is a major cause of ML performance degradation in healthcare. We will implement statistical alerts (e.g., population stability index or concept drift detectors) to trigger model recalibration or retraining when drift is detected. This ensures the model remains accurate and clinically safe over time, aligning with best practices for ML monitoring in medicine.

By diversifying training data and vigilantly watching for drift, our system aims to remain robust and generalizable. These steps address the often-cited generalizability gap in single-site studies, giving confidence that the triage model could perform well if deployed at other sites or under evolving conditions.

---

## Advanced Model Architecture and Explainability

Although our input is structured (binary and numeric triage features), we pursue a cutting-edge model design that is multimodal, temporal, and explainable, ensuring high performance without sacrificing interpretability:

- **Multimodal Fusion of Structured Features:** We treat different subsets of triage data as complementary "modalities" to inform the model. For example, vital signs over time (like heart rate trend during triage) can be processed by a recurrent neural network or Temporal CNN, while static information (age, sex) and categorical observations (yes/no symptoms, arrival mode) flow through feed-forward layers. These intermediate representations are then fused via an attention mechanism or gating network. Such an architecture imitates multimodal data fusion approaches used in health AI, which have shown improved outcomes over single-stream models. By designing the model to handle heterogeneous inputs (e.g., separate sub-networks for adult vs pediatric rules if needed), we capture the nuances of each data type. This temporal-and-structured fusion approach can uncover patterns like the trajectory of vital signs alongside symptom checklists, yielding a richer predictive signal than a flat model.
- **Explainable AI (XAI) Built-In:** To ensure clinicians trust and understand the AI recommendations, we will integrate explainability techniques at the core of the model. One approach is to use eXplainable Boosting Machines or rule-based models in tandem with a more complex model – for instance, an interpretable rule set extracted from the data to validate the black-box model's outputs. We will also apply SHAP (Shapley Additive Explanations) values or similar methods to the triage predictions, highlighting which features (e.g., "respiratory rate > 30" or "chest pain present") contributed most to a high-risk classification. In a study using SHAP on health check-up triage data, different clinical parameters were found to have age-dependent risk thresholds, suggesting the standard triage logic could be personalized. Following this insight, our system's explanations will not only show what factors led to a decision, but adapt to who the patient is. For example, if an elderly patient triggers a high-acuity alert due to mild tachycardia, the explanation might note "higher risk for age 80+ with HR=100" whereas for a younger adult that heart rate might not be flagged. This level of explanation (potentially using age-specific cutoff logic uncovered by XAI) helps clinicians validate that the AI's reasoning aligns with medical expectations or identifies when it doesn't.
- **Personalization Mechanisms:** We embed personalization into the model pipeline. Globally, the model will learn to adjust predictions based on personal factors (age, comorbidities) – for instance, distinguishing a child's vital sign norms from an adult's. Moreover, on an individual level, the system can learn from a patient's repeated visits or baseline readings if available (e.g., recognizing a chronic hypertension patient's "normal" BP is 150/90 and avoiding false alarms). This could be achieved via model fine-tuning on local data or by incorporating patient history features. As a simple example, the triage risk threshold for heart rate might be slightly higher for a known frequent runner (personal baseline bradycardia) versus a sedentary patient. The goal of personalization is to reduce one-size-fits-all rules and thereby improve accuracy for edge cases. Each recommendation the system makes could thus be more tailored to the individual, which is important in triage where variability is high.
- **LLM-Enhanced Module for Explanations:** While our primary model uses structured inputs, we will explore integrating a Large Language Model (LLM) component to improve user interaction and interpretability. One use-case is an explanation generator: after the model predicts a triage level, an LLM (e.g., a fine-tuned medical GPT) could take the key factors and generate a concise rationale in natural language. For example: "The patient's symptoms (fever and stiff neck) and very high heart rate indicate a possible meningitis or sepsis risk, suggesting an emergent triage level." This leverages the LLM's knowledge of medical logic to supplement the raw model output. Another use-case is handling any free-text that accompanies triage (like chief complaint or nurse's notes) – an LLM could interpret the text and map it to our structured features or provide a second opinion. Notably, recent research has demonstrated that LLMs like ChatGPT can match or even slightly outperform human triage nurses in acuity assignment when given patient narratives, and they did so with less bias across age/gender groups. This suggests that an LLM could serve as a valuable adjunct: either as a validation layer (checking consistency between the structured model's decision and what an LLM concludes from the case description) or as a means to reduce bias. We will proceed cautiously – ensuring the LLM's outputs are medically sound – but the synergy of deterministic structured models with the flexible reasoning of LLMs could yield a powerful, hybrid decision support tool.

In summary, our architecture strives for state-of-the-art performance (through deep learning and multimodal fusion) while maintaining clinical explainability and adaptability. Clinicians will not only receive a triage recommendation, but also an intelligible reasoning and the ability to drill down into which signs led to that suggestion. This transparency is crucial for real-world adoption of AI in emergency care.

---

## Edge Intelligence for Low-Latency, Resilient Deployment

Triage is a real-time task – any decision support must produce results in seconds without relying on distant servers. We embrace edge computing principles to meet these needs, deploying models on local hardware and enabling on-device learning:

- **Real-Time, On-Device Inference:** The triage model will be hosted at the edge (e.g., on a hospital computer or a portable device in the triage area) to eliminate network latency. By computing predictions locally, we ensure sub-second responses, which is vital in emergencies. Edge deployment also means the system remains operational even if the internet or cloud services go down. For instance, during a disaster scenario with connectivity loss, the triage tool would still function and guide urgent decisions. Our design minimizes the computational footprint so it can run on modest hardware (potentially even a tablet), bringing AI directly to the point-of-care.
- **Offline Mode and Data Security:** All necessary models and data processing pipelines will reside on the device, allowing an offline mode. Patient data never leaves the hospital network, addressing privacy concerns inherently. This also aligns with regulations like HIPAA, since PHI (protected health info) isn't transmitted externally. The system can cache updates and sync when connection is restored, but core functionality does not depend on constant connectivity. By being self-contained, the triage support tool offers high availability and data control.
- **On-Device Model Adaptation:** A novel aspect is enabling the model to learn and adapt locally using new data, a concept known as on-device or federated learning (discussed more in the next section). Over time, as the device accumulates more triage cases (with outcomes), it can perform periodic local training updates. This allows personalization to the hospital's patient population without sending data to the cloud. For example, if the hospital sees an influx of a new illness (say a local outbreak causing unusual symptom patterns), the edge model can adapt to these cases quickly. We will implement this carefully to avoid overfitting or drift – likely using a strategy of incremental learning with regularization and keeping a hold-out set to ensure performance doesn't degrade. The ability for edge devices to update models also ties into resilience: if central coordination is unavailable, the device isn't stuck with a stale model – it continuously self-improves in a governed manner. This approach is inspired by emerging on-device learning techniques that highlight personalization, latency benefits, and privacy of local training.
- **Resource-Optimized AI (Latency/Power Constraints):** We will employ model compression and optimization to ensure the AI runs efficiently on edge hardware. Techniques include quantizing model weights (e.g., 8-bit integers instead of 32-bit floats) to reduce memory and improve speed, pruning redundant neurons, and using light architectures (such as MobileNet-style networks or knowledge distillation into a smaller model). Model compression can dramatically shrink the model size and computational load without significant performance loss. We will evaluate the trade-off curve between speed and accuracy: our target is to meet strict latency (e.g. <100ms per inference) and low CPU usage for battery-powered devices, while maintaining high decision accuracy. If needed, we'll consider hardware acceleration (like running on an edge TPU or GPU). Additionally, the system will have a "graceful degradation" mode – e.g., if the environment is extremely resource-constrained, a simpler fallback model or rule-based triage can be used as backup. These measures ensure the AI system is robust and fast enough for real-world ED triage, where every second counts and computing resources may be limited.

By incorporating edge intelligence, our triage support tool will be immediately responsive, locally autonomous, and privacy-preserving. This design aligns with the growing trend of moving AI computation to edge devices in healthcare for reliability and speed. It also provides a platform to test advanced concepts like on-device fine-tuning and TinyML in a clinically important application.

---

## Federated Learning with Privacy and Robustness

To further future-proof the system for multi-center use and leverage collaboration without data sharing, we integrate a Federated Learning (FL) paradigm. Even though we have data from a single hospital, we simulate a federated scenario to explore its benefits:

- **Simulated Multi-Node Training:** We will partition the single-hospital data into multiple virtual clients (for instance, by department, by time period, or by patient subgroups) and perform federated learning across these nodes. This means each client trains the model on its own subset and only model updates (not raw data) are sent to a central aggregator. Simulating FL on one hospital's data provides a testbed for how the system would behave if deployed across multiple hospitals in the future. It also helps enforce modularity (since even internal partitions must train robust models). By comparing a federated training run to a standard centralized training, we can quantify any performance differences and ensure our model is FL-ready. Notably, FL in healthcare is gaining traction as a way to utilize diverse data silos while respecting privacy – our project can be an exemplar by demonstrating FL on triage data.
- **Privacy Preservation:** In a real multi-hospital setup, FL would allow each hospital to keep patient records on-premise and only share learned parameter updates. This significantly reduces legal and ethical barriers to using sensitive health data. Our implementation will simulate this benefit – e.g., if we divide data by adult vs pediatric patients (two nodes), no raw pediatric data "sees" the adult data, yet a combined model is learned. We adhere to FL protocols where the server aggregates weights (e.g., via Federated Averaging) and sends back the global model. Because no identifiable data leaves the site, FL offers compliance with data protection regulations and alleviates the need for arduous data use agreements between institutions. We will also incorporate differential privacy in the updates if feasible (adding noise to gradients) to further ensure that individual patient info cannot be reconstructed from model parameters.
- **Poisoning Defense and Robust Aggregation:** A well-known concern in FL is the possibility of a malicious or corrupted client sending poisoned model updates to skew the global model. To address this, we will implement robust aggregation techniques. For example, we can use the Krum algorithm or coordinate-wise median instead of plain averaging – these methods can down-weight or filter out anomalous client updates that deviate significantly from others. In our simulated environment, we can even test a scenario where one "node" feeds incorrect data (acting as an attacker) and verify that our defenses (like anomaly detection on updates, or requiring a certain agreement among clients) neutralize the effect. By doing so, we build a triage model training process that is resilient to both unintentional data issues and security threats. This is important if, for instance, one hospital's data is incomplete or a user mistakenly labels data – the global model should not be overly affected by any single problematic source.
- **Communication Efficiency:** Federated learning can be communication-intensive, so we plan to use strategies to minimize bandwidth and update frequency, which is especially relevant if edge devices are communicating over limited networks. Techniques include compressing model updates (sending only significant weight changes or using quantized updates) and asynchronous update handling (clients send updates on their own schedule, and the server aggregates periodically). We draw on frameworks like FedAvg which already drastically cut required communication rounds for convergence. In essence, our system will be optimized such that if it were training across, say, 5 emergency departments, it wouldn't overload the network or require constant syncing – perhaps aggregating models nightly or using peer-to-peer update relays. This communication-aware design ensures that FL remains feasible in practice, aligning with research that emphasizes efficiency in distributed learning.
- **Fairness in Federated Models:** (Relates to both FL and our ethical goals) We will monitor the federated model's performance on each client's data to detect if the model unduly favors one subpopulation over another – an issue that can arise if one client dominates the gradient updates. If needed, we will explore federated fairness techniques (such as equalizing performance or introducing constraints that maximize the minimum performance across clients). For example, ensuring that a model trained from both adult and pediatric data does not become biased toward whichever group has more data. This way, federation not only preserves privacy but can enhance equity, by exposing the model to varied demographics and then adjusting to serve them all adequately.

By incorporating federated learning, our research application stays at the forefront of collaborative healthcare AI. It shows how a triage decision support tool could be trained across multiple hospitals without centralizing data, an attractive proposition for large health systems or regions looking to share insights. Importantly, our emphasis on privacy and security in FL aligns with JBHI's focus on safe and ethical AI in health informatics.

---

## Comprehensive Evaluation Strategy

Technical innovation alone is not enough – rigorous evaluation on clinical efficacy, human factors, and ethics is essential. We outline a comprehensive evaluation plan covering prospective validation, user experience, and bias analysis:

- **Clinical Validation (Prospective/Simulation):** We will validate the system's triage recommendations against real patient outcomes and expert judgments. Ideally, a prospective study will be conducted: for example, deploying the decision support in a trial where it runs in parallel with nurses (without actually intervening at first) to compare its triage level suggestions to the nurses' decisions and patient results. Key metrics will include accuracy in predicting high-acuity cases, under-triage/over-triage rates, and impacts on ED flow (e.g., does early identification of critical patients improve time-to-treatment?). If immediate prospective testing is challenging, we will do a retrospective replay evaluation: using historical ED cases, we simulate how the model would have triaged them and compare that to actual outcomes. This addresses the clinical relevance – we expect our model to flag patients who needed ICU or emergent intervention with higher sensitivity than standard triage, while maintaining specificity. In fact, evidence from LLM-based triage trials shows AI can identify high-acuity patients that nurses might miss (in one study, ChatGPT significantly outperformed nurses in recognizing critical cases). Our evaluation will similarly assess if the AI reduces missed critical illness. We will also measure improvements in throughput (if using the AI could hypothetically fast-track certain patients). Any prospective trial will follow appropriate ethical approvals and oversight, and we will use reporting standards like CONSORT-AI to document it.
- **Usability and Workflow Integration:** A mixed-methods usability assessment with the end-users (triage nurses, physicians) is crucial. We will conduct usability testing sessions where clinicians interact with the system in a controlled setting (for instance, using standardized patient scenarios). During these sessions, we'll observe and record how the tool affects their workflow: does it speed up triage? Is the interface clear? Do they understand the explanations provided? We will collect subjective feedback on trust and ease-of-use via surveys and interviews. Prior work suggests that medical staff can have a high acceptance of AI triage if it demonstrates reliability – one survey found an 77% acceptance rate among staff for an AI-driven triage, with nearly half even preferring AI triage in some cases. This is encouraging, but we will probe specific concerns such as: Do nurses feel the AI is helping or second-guessing them? How much autonomy would they give it in decision-making? The system's UI will be iteratively improved based on this feedback (for example, adjusting alert presentation, adding the ability to drill down into rationale, etc.). We will also evaluate training needs – ensuring that with minimal training, a nurse can use the system effectively. By involving end-users early and often, we aim for a human-centered design that aligns the AI with actual clinical practice, increasing the likelihood of adoption.
- **Ethical and Bias Analysis:** We incorporate an explicit review for ethical issues and potential biases. This involves analyzing model performance across different patient subgroups (age, gender, ethnicity, socioeconomic status if available). We will leverage the explainability to detect patterns like, "Is the model systematically assigning lower acuity to certain groups when controlling for clinical factors?" If any such bias is found, we will investigate the cause (data imbalance? a proxy feature?) and adjust the model or preprocessing to mitigate it. For example, if the model appeared to under-triage younger adults compared to older adults with similar vitals (a scenario observed with human triage biases), we would address that by recalibrating risk scores by age. We will also convene an ethics panel or at least seek consultation on matters like: how to ensure the AI's recommendations do not inadvertently disadvantage anyone, how to maintain transparency in how the AI was developed (to avoid "AI mystique" in patient care), and how to handle cases of disagreement between AI and nurse (safety net protocols). All decisions made by the AI will be logged for audit. Furthermore, our evaluation will check for safety – e.g., no case where the AI recommends a dangerously low priority for a patient who actually needed urgent care. Any such occurrences will be treated as sentinel events, prompting immediate model review. The ethical review also covers patient privacy (the system will be assessed for compliance with privacy principles, which is inherently strong due to on-device processing and FL). By performing an extensive bias and ethics audit, we ensure the system is not only effective but also aligns with values of equity and do-no-harm. We will document this in our publication (JBHI readers expect discussion of bias and limitations).
- **Performance Benchmarks and Statistical Rigor:** As part of evaluation, we will benchmark our approach against existing methods. This could include comparing to traditional triage tools or simpler models (like logistic regression on the same data) to quantify improvement. We plan to use proper validation techniques (cross-validation, nested CV for model selection, and a hold-out test set or external dataset if attainable) to report reliable performance estimates. We will also incorporate confidence intervals and, where relevant, statistical tests (e.g., comparing ROC curves) to show significance of improvements. If performing a prospective trial, appropriate sample size calculations and endpoints will be predefined, following guidelines (CONSORT-AI extension mandates clear reporting of trial design and analyses).

Our comprehensive evaluation ensures the research is grounded in clinical reality and meets publication standards. By demonstrating efficacy, safety, usability, and fairness, we strengthen the case that this AI triage system is ready for real-world use and is of the caliber expected by IEEE JBHI and the healthcare community.

---

## Open Science and Transparent Reporting

To align with modern scientific best practices and JBHI expectations, we commit to making this research as open and transparent as possible:

- **Open-Source Code and Synthetic Data:** We will release the core model code (e.g., model architecture, training scripts) under an open-source license on a platform like GitHub. Alongside code, we will publish a synthetic version of the dataset (since actual patient data can't be open-sourced due to privacy). The synthetic data will be generated to have similar statistical properties as the real triage data, enabling other researchers to replicate our experiments. By providing a realistic synthetic dataset and clear instructions, we facilitate validation and extension of our work by others, which is a key aspect of open science. Open sourcing also includes sharing any custom synthetic data generation framework we develop (contributing back to the community working on healthcare data simulation). This practice is encouraged in new reporting guidelines like TRIPOD-AI, which emphasize open science as crucial for prediction model research.
- **Reporting Guidelines (CONSORT-AI, TRIPOD-ML):** We will meticulously follow relevant reporting standards to ensure our publication is transparent and complete. For the predictive model development aspects, we will use the TRIPOD-ML (also known as TRIPOD-AI) checklist. This means we will report details such as: dataset characteristics, handling of missing data, model tuning procedure, validation strategy, and performance metrics with confidence intervals. Adhering to TRIPOD-ML ensures that readers and reviewers can fully appraise the validity of the model and its potential biases. If we conduct a clinical trial or prospective study of the tool, we will report it according to the CONSORT-AI extension. The CONSORT-AI guidelines call for describing the AI intervention thoroughly (e.g., version of model, how it was integrated into workflow, any human-AI interaction details) and any post-hoc analyses of errors. By following these guidelines, we increase the likelihood that our submission meets JBHI's rigour criteria and also set an example of proper reporting for AI in healthcare.
- **Model Cards and Documentation:** We will publish a Model Card for the triage model – a practice recommended for transparent AI. The model card will detail the model's intended use, architecture, training data scope, performance on various subgroups, ethical considerations (like fairness), and limitations. It will also include caveats such as "This model is not a substitute for clinical judgment" to guide safe use. Additionally, we'll provide documentation on how to deploy the model on an edge device, and how to reproduce the federated learning results (possibly packaging a demo with a few synthetic client datasets). This level of documentation supports reproducibility, which is part of open science values.
- **CONSORT-AI and Open Science Links:** We note that recent works (like the TRIPOD+AI statement) strongly advocate for open science in AI publications. By pre-registering our prospective evaluation (if applicable) and possibly sharing the protocol (following SPIRIT-AI for trial protocols), we ensure transparency from the start. We may also choose to publish in open-access venues or at least share a preprint to disseminate results widely. Our commitment is that nothing about the model will be a "black box" in print – all relevant technical and evaluation details will be openly available for scrutiny.

Embracing open science not only increases the impact of our research (allowing others to build on it), but also aligns with the trustworthiness and reproducibility that top journals like JBHI expect. The end result will be a well-documented, openly accessible triage decision support framework that the community can examine and evolve.

---

## Novel Research Directions and Questions

Finally, our project opens several new research avenues that push the envelope of both technical and clinical knowledge in AI-driven triage. We highlight a few novel questions that we will explore:

- **Fairness in Federated Triage Models:** How can we ensure and measure fairness across different client populations in a federated learning setup? In our simulated multi-site training, we will investigate methods to detect if the global model is unfairly favoring the data-rich client or if any systemic bias emerges (for example, a model that works better for adults from urban populations vs. pediatric or rural). We'll experiment with fairness-aware FL algorithms (like adjusting client weights or incorporating a fair aggregation objective) to achieve more balanced performance. This study can yield insights into group fairness in distributed healthcare AI – e.g., does federated training inherently increase fairness by training on diverse data, or do we need to add corrections? Given triage decisions directly impact patient outcomes, ensuring fairness is ethically paramount and scientifically challenging, making this a cutting-edge question.
- **Real-Time Interpretability of Boolean Rule Chains:** Triage algorithms often resemble decision trees or rule sets (e.g., IF fever AND stiff neck THEN high priority). We aim to connect our model's behavior to human-understandable Boolean rule chains in real time. One novel approach is to use Boolean Rule Column Generation or two-level Boolean rule learning techniques on the model's decision boundary to extract a simplified set of logical rules that approximate the model. We will research whether we can present these rules as explanations on-the-fly – for instance, the system might say: "Triggered Rule: IF (Chest Pain = Yes) AND (Troponin test pending) AND (Age > 50) THEN triage = High (this patient meets these conditions)". This would effectively mirror the model's reasoning in a clinician-friendly format. The challenge is balancing fidelity (the rules should reflect the model accurately) and simplicity (rules should be concise). We will explore using an LLM to help articulate complex logic into a narrative form as well. Real-time interpretability of complex models via Boolean logic is a novel research area that can greatly increase trust in AI – our work could demonstrate a feasible implementation of this in an emergency care setting.
- **Compressing Models under Latency/Power Constraints:** We raise the question: How much can we compress and speed up a triage model without significantly sacrificing accuracy? This involves systematically applying compression techniques (quantization, pruning, knowledge distillation) and measuring triage performance trade-offs. We will experiment with ultra-light models that could even run on handheld devices or wearables used in pre-hospital triage. The novel aspect is an analysis of the accuracy vs. efficiency frontier for this clinical task. We might find, for example, that a model quantized to 4-bit weights and pruned to 10% of its original size still achieves 95% of the full model's AUC – which would be a valuable insight for deploying AI in low-resource settings. Conversely, we will identify the point at which compression starts to critically hurt decision accuracy for edge scenarios. This research could guide others in making model compression choices for health AI, contributing to the TinyML for healthcare knowledge base.
- **Continual Learning and Triage Concept Drift:** Triage criteria and patient profiles may shift (think of COVID-19 emergence changing triage dynamics overnight). We plan to study continual learning strategies where the model updates itself with new data continuously (on-device or federated) while avoiding catastrophic forgetting of previous knowledge. This is a novel challenge: ensuring an evolving model maintains consistency and safety. We will test techniques like rehearsal (keeping a cache of past cases) or regularization methods that prevent the model from drifting too far from its initial calibration. The research question here is how to safely do online learning in a high-stakes domain like triage – how to detect when the model's updates might be leading it astray and institute a fail-safe (such as human review or reverting to a previous model checkpoint). Our findings will inform the design of lifelong learning systems in healthcare, a relatively uncharted territory.
- **Impact on Workflow and Decision Psychology:** As a more qualitative direction, we are interested in how introducing an AI decision support changes the triage process and decision-making psychology of nurses/doctors. Does it reduce cognitive load or potentially introduce automation bias (over-reliance on the AI)? We will formulate research around user behavior: e.g., measuring how often clinicians adhere to vs. override the AI suggestion, and their rationale. Understanding this interaction can help improve AI advice presentation (maybe the AI should express uncertainty or provide pros/cons). This intersects human factors research and is novel in the context of AI-assisted triage – contributing insights on the optimal way to blend AI with human expertise on the frontline.

By embedding these research questions into our project, we ensure it's not just a one-off application but a source of new knowledge for the field. Our work will delve into fairness in distributed learning, innovative explainability, resource-efficient AI, and human-AI collaboration in a high-pressure environment. Such contributions are scientifically exciting and increase the likelihood of our work being accepted in a top-tier venue like JBHI, which values both technical depth and real-world impact.

---

## Conclusion

In designing this advanced triage decision support system, we bring together a suite of state-of-the-art techniques – from synthetic data augmentation and federated edge learning to explainable and personalized modeling – all tailored to the critical use-case of emergency triage. The research is technically rigorous, exploring cutting-edge AI (LLMs, XAI, TinyML) and addressing open questions, but it is also clinically grounded, aiming to improve patient outcomes and workflow in a tangible way. By adhering to high standards of evaluation and transparency, we position this work squarely at the intersection of biomedical informatics innovation and practical healthcare utility. This comprehensive approach is what makes the project novel and impactful, aligning perfectly with the scope of IEEE JBHI and pushing the frontier of intelligent health systems for acute care.

---

**Sources:** The design and claims are informed by current literature on healthcare AI generalizability, emergency triage modeling, edge and federated learning in medicine, and guidelines for trustworthy AI evaluation, as cited throughout this document. 